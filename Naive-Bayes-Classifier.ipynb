{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T23:48:29.651929Z",
     "start_time": "2024-10-28T23:48:26.077193Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "test_df = pd.read_csv('dataset/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T23:50:06.810842Z",
     "start_time": "2024-10-28T23:50:05.971051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 18280\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>3</td>\n",
       "      <td>The|Rock|is|destined|to|be|the|21st|Century|'s...</td>\n",
       "      <td>0.69444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>4</td>\n",
       "      <td>The|gorgeously|elaborate|continuation|of|``|Th...</td>\n",
       "      <td>0.83333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singer\\/composer Bryan Adams contributes a sle...</td>\n",
       "      <td>3</td>\n",
       "      <td>Singer\\/composer|Bryan|Adams|contributes|a|sle...</td>\n",
       "      <td>0.62500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "      <td>2</td>\n",
       "      <td>You|'d|think|by|now|America|would|have|had|eno...</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "      <td>3</td>\n",
       "      <td>Yet|the|act|is|still|charming|here|.</td>\n",
       "      <td>0.72222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  \\\n",
       "0  The Rock is destined to be the 21st Century 's...      3   \n",
       "1  The gorgeously elaborate continuation of `` Th...      4   \n",
       "2  Singer\\/composer Bryan Adams contributes a sle...      3   \n",
       "3  You 'd think by now America would have had eno...      2   \n",
       "4               Yet the act is still charming here .      3   \n",
       "\n",
       "                                              tokens    score  \n",
       "0  The|Rock|is|destined|to|be|the|21st|Century|'s...  0.69444  \n",
       "1  The|gorgeously|elaborate|continuation|of|``|Th...  0.83333  \n",
       "2  Singer\\/composer|Bryan|Adams|contributes|a|sle...  0.62500  \n",
       "3  You|'d|think|by|now|America|would|have|had|eno...  0.50000  \n",
       "4               Yet|the|act|is|still|charming|here|.  0.72222  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_vocab(train_df):\n",
    "    tokens = []\n",
    "    for _, row in train_df.iterrows():\n",
    "        row_tokens = row['tokens'].split('|')\n",
    "        tokens.extend(row_tokens)\n",
    "    return np.unique(tokens) \n",
    "\n",
    "def get_number_of_words_in_class(df):\n",
    "    class_count = {}\n",
    "    for _, row in df.iterrows():\n",
    "        row_tokens = row['tokens'].split('|')\n",
    "        if row['label'] in class_count:\n",
    "            class_count[row['label']] += len(row_tokens)\n",
    "        else:\n",
    "            class_count[row['label']] = len(row_tokens)\n",
    "    return class_count   \n",
    "\n",
    "# generate vocabulary\n",
    "vocab = generate_vocab(train_df)\n",
    "print(f'Vocabulary size: {len(vocab)}')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T23:55:32.112249Z",
     "start_time": "2024-10-28T23:50:10.108724Z"
    }
   },
   "outputs": [],
   "source": [
    "n_doc = len(train_df)\n",
    "log_prior = np.log2(train_df['label'].value_counts().sort_index() / n_doc).tolist()\n",
    "log_likelihood = np.zeros((len(vocab), 5))\n",
    "\n",
    "class_count = get_number_of_words_in_class(train_df)\n",
    "\n",
    "# Precompute counts for each word in each class\n",
    "for c in range(5):  # 5 classes\n",
    "    # Filter once by class\n",
    "    class_df = train_df[train_df['label'] == c]\n",
    "    \n",
    "    # Count occurrences of each word in vocab for this class\n",
    "    word_counts = {w: class_df['sentence'].apply(lambda x: x.count(w)).sum() for w in vocab}\n",
    "    \n",
    "    # Calculate log likelihood for each word in vocab\n",
    "    for index, w in enumerate(vocab):\n",
    "        n_wc = word_counts[w]\n",
    "        log_likelihood[index][c] = np.log2((n_wc + 1) / (class_count[c] + len(vocab)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Test Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T23:59:28.548241Z",
     "start_time": "2024-10-28T23:59:28.535358Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def test_naive_bayes(testdoc, logprior, loglikelihood, C, V):\n",
    "    # Create a dictionary to map words to their indices for quick lookup\n",
    "    word_to_index = {word: i for i, word in enumerate(V)}\n",
    "    sum_scores = np.zeros(len(C))  # Initialize scores for each class\n",
    "    \n",
    "    for c in range(len(C)):\n",
    "        # Initialize score with the log prior for the class\n",
    "        sum_scores[c] = logprior[c]\n",
    "        \n",
    "        for word in testdoc.split():  # Split the test document into words\n",
    "            if word in word_to_index:  # Check if the word is in V\n",
    "                # Update score by adding loglikelihood of the word given the class\n",
    "                index = np.where(vocab == word)[0]\n",
    "                sum_scores[c] += loglikelihood[index[0]][c]\n",
    "                \n",
    "    # Return the class with the maximum score\n",
    "    return np.argmax(sum_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7468398876404494\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for _, row in train_df.iterrows():\n",
    "    predicted_class=test_naive_bayes(row['sentence'], log_prior, log_likelihood, [0, 1, 2, 3, 4], vocab)\n",
    "    if predicted_class == row['label']:\n",
    "        cnt+=1\n",
    "\n",
    "# compute accuracy\n",
    "accuracy = cnt/len(train_df)\n",
    "\n",
    "print(f'Train Accuracy: {accuracy}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.38552036199095024\n",
      "Number of wrong predicted sentences:1358\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for _, row in test_df.iterrows():\n",
    "    predicted_class=test_naive_bayes(row['sentence'], log_prior, log_likelihood, [0, 1, 2, 3, 4], vocab)\n",
    "    if predicted_class == row['label']:\n",
    "        cnt+=1\n",
    "\n",
    "# compute accuracy\n",
    "accuracy = cnt/len(test_df)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "print(f'Number of wrong predicted sentences:{len(test_df)-cnt}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
